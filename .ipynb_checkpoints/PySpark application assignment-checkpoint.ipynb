{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The top 15 movies on IMDb\n",
    "\n",
    "## Main objectives: \n",
    "    1. Fetch top 15 movies with a minimum of 100 votes\n",
    "    2. Ranking = (numVotes / averageNumberOfVotes) * averageRating\n",
    "    3. List of the title of these top 15 movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the files into Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from functions import filter_100_votes, tuple_conversion, filter_movies, find_mean, rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point to the files with abspath. Then read the .tsv file containing the rating informations into a dataframe and then convert it into rdd type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tt9916778', '7.3', '24'],\n",
       " ['tt9916766', '6.9', '14'],\n",
       " ['tt9916720', '6.0', '57']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "path_to_ratings = pathlib.Path('raw_data/title.ratings.tsv')\n",
    "abs_path = os.path.abspath(path_to_ratings)\n",
    "df_ratings = spark.read.csv(abs_path, sep=r'\\t', header=True).select('tconst','averageRating','numVotes')\n",
    "rdd_ratings = df_ratings.rdd.map(list)\n",
    "rdd_ratings.top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then do the same for the .tsv file containing the tile informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tt9916880', 'tvEpisode', 'Horrid Henry Knows It All'],\n",
       " ['tt9916856', 'short', 'The Wind'],\n",
       " ['tt9916852', 'tvEpisode', 'Episode #3.20']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_titles = pathlib.Path('raw_data/title.basics.tsv')\n",
    "abs_path = os.path.abspath(path_to_titles)\n",
    "df_titles = spark.read.csv(abs_path, sep=r'\\t', header=True).select('tconst','titleType','primaryTitle')\n",
    "rdd_titles = df_titles.rdd.map(list)\n",
    "rdd_titles.top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter all movies, short movies, tv episodes, etc. so that only those that have 100 or more number of votes remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_ratings = filter_100_votes(rdd_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data, in order to do a complete join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_ratings_pair = tuple_conversion(rdd_ratings)\n",
    "rdd_titles_pair = tuple_conversion(rdd_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join data using the join function, using the 'tconst' as the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd_joined = rdd_ratings_pair.join(rdd_titles_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â Filter the joined data so that only movies are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_movies = filter_movies(rdd_joined)\n",
    "rdd_movies.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the ranking using the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_15_ranked = rank(rdd_movies).take(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through the final list and print out top 15 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_term in top_15_ranked:\n",
    "    print(each_term[1][1][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
